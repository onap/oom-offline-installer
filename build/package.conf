# For the packaging script it is expected that all artifacts are present on local file system.
# Artifacts include:
#  - installer source code (this git repository content)
#  - all binary artifacts pre-downloaded from internet (docker images, rpm packages, npm packages, Maven artifacts etc.)

# Script will create 3 packages:
# offline-${PROJECT_NAME}-${PROJECT_VERSION}-sw.tar
#       - installer code (ansible dir in this git repo)
#       - Files/dirs defined by APP_CONFIGURATION if any.
#       - Directory content of HELM_CHARTS_DIR if defined.
# offline-${PROJECT_NAME}-${PROJECT_VERSION}-resources.tar
#       - Directory content of APP_BINARY_RESOURCES_DIR if defined.
# offline-${PROJECT_NAME}-${PROJECT_VERSION}-aux-resources.tar
#       - Files defined by APP_AUX_BINARIES if any.

###########################
# Application Helm charts #
###########################

# Provide application installed to Kubernetes cluster. Helm chart is the supported format https://helm.sh/.
# Directory provided here must contain all the Chart directories of the application (https://docs.helm.sh/developing_charts/#charts) and Makefile.
# E.g. in case of ONAP oom repo it will be the content of kubernetes directory.
#HELM_CHARTS_DIR=~/myclones/casablanca_oom/

#####################################
# Application install configuration #
#####################################

# APP_CONFIGURATION array variable can be used to provide files/directories
# into sw package available for the Ansible process to consume.
# The main configuration for you application is a yml file
# "application_configuration.yml" (name of file can be anything) where user
# need to provide values to control ansible installer process. Yml file is given
# as command line parameter to ansible run.
# See more from UserGuide documentation (LINK HERE) how to use installer.
# Available configuration parameters user can configure is seen from group_vars files:
#   ansible/group_vars/all.yml
#   ansible/group_vars/infrastucture.yml
#   ansible/group_vars/kubernetes.yml
# Additionally user can optionally provide own ansible roles code to customize install process.
# At the moment 2 custom ansible roles are supported pre and post install roles, which are
# run by installer prior Helm install and after Kubernetes app has been installed.
# In application_configuration.yml those role names are configured with variables:
#   application_pre_install_role: my-pre-install-role
#   application_post_install_role: my-post-install-role
# And according to Ansible functionality, roles' code must be placed to directories
# with the same name.
#APP_CONFIGURATION=(
#    <offline-installer-clone>/config/application_configuration.yml
#    <offline-installer-clone>/patches/onap-casablanca-patch-role
#    ~/myappfiles/my-post-install-role
#)

# APP_BINARY_RESOURCES_DIR is variable to directory containing directories and files for offline
# installer infra and the the application run in that infra.
# Currently mixed with infra and app binaries to same, maybe to be separated in the future.
# Following directories and files are expected:
#       downloads        ... directory with exacutable binaries for offline infra usage (e.g. rancher, kubectl, jq, helm)
#       git-repo         ... directory with git repos for application needs to be simulated
#       http             ... directory with http simulation files (e.g. Maven artifacts are simulated here)
#       offline_data     ... directory with offline infra specific docker images
#       pkg              ... directory with rpm/deb packages mainly for offline infra
#       nexus_data.tar   ... tar file with pre-generated nexus blobs containing e.g. docker images for the application.
#APP_BINARY_RESOURCES_DIR=~/myappfiles/all_binaries

# APP_AUX_BINARIES is array variable for additional application files.
# Docker images supported currently in tar format.
#APP_AUX_BINARIES=(
#    ~/myappfiles/docker_images_populated_runtime/aaa-component-0.0.1.tar
#    ~/myappfiles/docker_images_populated_runtime/xyz-component-0.0.1.tar
#)
