{
  "comments": [
    {
      "key": {
        "uuid": "fe5afe7c_b7a39438",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 15,
      "author": {
        "id": 5019
      },
      "writtenOn": "2019-04-23T10:52:09Z",
      "side": 1,
      "message": "Ok, i do not understand that paragraph. Do you mean you cannot put control plane on more than one node, or cannot put a control plane on nodes with etcd if there is more than one control plane, or what? Any links/references?\nAlso, isn\u0027t it the case that etcd in general should not be put on workers, at least not on these running workloads, because of performance implications? That is what i\u0027ve once heard/read in openshift docs, and openshift is indeed enhanced kubernetes. In that case we could go with one etcd on infra + control plane also on infra. Any clue?",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "da21e914_b44cc2d4",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 15,
      "author": {
        "id": 3957
      },
      "writtenOn": "2019-04-23T11:35:46Z",
      "side": 1,
      "message": "About the last sentence, do you propose we run etcd on offline-infra node? Should\u0027t we still keep offline installer nodes (infra) out of Kubernetes nodes?",
      "parentUuid": "fe5afe7c_b7a39438",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "210df878_72123ba2",
        "filename": "/COMMIT_MSG",
        "patchSetId": 1
      },
      "lineNbr": 15,
      "author": {
        "id": 5019
      },
      "writtenOn": "2019-04-23T12:39:02Z",
      "side": 1,
      "message": "I do not propose anything, I am just trying to understand this part of commit message.",
      "parentUuid": "da21e914_b44cc2d4",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "909e2899_6bf2eb85",
        "filename": "ansible/roles/rke/tasks/rke_config.yml",
        "patchSetId": 1
      },
      "lineNbr": 12,
      "author": {
        "id": 3957
      },
      "writtenOn": "2019-04-23T11:53:53Z",
      "side": 1,
      "message": "is there a way to avoid there shell commands?",
      "range": {
        "startLine": 12,
        "startChar": 2,
        "endLine": 12,
        "endChar": 37
      },
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "999df07c_280984da",
        "filename": "ansible/roles/rke/tasks/rke_config.yml",
        "patchSetId": 1
      },
      "lineNbr": 12,
      "author": {
        "id": 5019
      },
      "writtenOn": "2019-04-23T12:39:02Z",
      "side": 1,
      "message": "nope. if you do not assume known_hosts for infra is already valid (note ansible is run from a different host so it is not necessarily valid) then you need ssh-keyscan.",
      "parentUuid": "909e2899_6bf2eb85",
      "range": {
        "startLine": 12,
        "startChar": 2,
        "endLine": 12,
        "endChar": 37
      },
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "65dc28c0_ae914bd7",
        "filename": "ansible/roles/rke/tasks/rke_config.yml",
        "patchSetId": 1
      },
      "lineNbr": 32,
      "author": {
        "id": 5019
      },
      "writtenOn": "2019-04-23T10:52:09Z",
      "side": 1,
      "message": "Ok. not sure why rke is copied to user homedir as opposed to copying it just to /usr/local/bin? not every distribution has $HOME/bin in default $PATH so you cannot rely on that being true... I will probably change that behavior.",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "39d2208a_7636d9f6",
        "filename": "ansible/roles/rke/tasks/rke_config.yml",
        "patchSetId": 1
      },
      "lineNbr": 32,
      "author": {
        "id": 4886
      },
      "writtenOn": "2019-05-02T08:45:46Z",
      "side": 1,
      "message": "to contain rke stuff inside one intuitive place and not pollute the system",
      "parentUuid": "65dc28c0_ae914bd7",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "cbc60f0a_f8151567",
        "filename": "ansible/roles/rke/tasks/rke_config.yml",
        "patchSetId": 1
      },
      "lineNbr": 32,
      "author": {
        "id": 5019
      },
      "writtenOn": "2019-05-06T09:11:03Z",
      "side": 1,
      "message": "Well, considering that kubectl and helm are in /usr/local/bin, it is inconsistent if rke is suddenly placed somewhere else. We rather do not change more of the installer in similar ways.",
      "parentUuid": "39d2208a_7636d9f6",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "bb0271f7_911f3426",
        "filename": "ansible/roles/rke/tasks/rke_deploy.yml",
        "patchSetId": 1
      },
      "lineNbr": 8,
      "author": {
        "id": 3957
      },
      "writtenOn": "2019-04-23T11:53:53Z",
      "side": 1,
      "message": "Some follow up should be here, right? E.g. ensure with kubectl that deployment is working.\n\nkubectl --kubeconfig .kube_config_cluster.yml get all --all-namespaces",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "c5d99363_7c79163a",
        "filename": "ansible/roles/rke/tasks/rke_deploy.yml",
        "patchSetId": 1
      },
      "lineNbr": 8,
      "author": {
        "id": 5019
      },
      "writtenOn": "2019-04-23T12:39:02Z",
      "side": 1,
      "message": "Not sure. Actually what rke does is performing health checks on everything it runs, so I believe that if it finished normally, we have some kind of guarantee that the deployment is successful. The only thing is for example, that it doesn\u0027t quite fail if it fails to connect to some node, it just skips it, not sure if this can be changed.",
      "parentUuid": "bb0271f7_911f3426",
      "revId": "c6a7c353be1b38bc1f2b6cd433daaa3b024effed",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    }
  ]
}